{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Transfer Learning Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chairiq/Pulmonary-embolism-in-ctscans-dl/blob/main/Transfer_Learning_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl3kGGJWV9_e"
      },
      "source": [
        "# CT-Scan images clasification with Transfer Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJunDoyXgpqv"
      },
      "source": [
        "# 0) Connect to your cloud storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3XTY578xxIc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_GJJz1UV5O1"
      },
      "source": [
        "## 1) Import libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kIXkFAlNV5O6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import InceptionV3,VGG16,ResNet50,MobileNetV2, NASNetMobile\n",
        "from tensorflow.keras.applications import NASNetLarge, InceptionResNetV2, DenseNet121, EfficientNetB2, EfficientNetB2\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers as lay\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "import shutil\n",
        "import zipfile\n",
        "import urllib\n",
        "import urllib.request\n",
        "import glob\n",
        "from google.colab import files\n",
        "\n",
        "K.clear_session()\n",
        "print(\"Tensorflow Version: {}\".format(tf.__version__))\n",
        "print(\"Keras Version: {}\".format(keras.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9zcUG3KYQuS"
      },
      "source": [
        "## 2) Get dataset\n",
        "The dataset should cosist of two classes (two different subfolders, one for each class):\n",
        "1.   First class: Images (from CT-Scans) with pulmonary embolism\n",
        "2.   Second class: Images (from CT-Scans) without pulmonary embolism\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf6FV6tlTelX"
      },
      "source": [
        "G_DRIVE_DIR = 'my_path_to_the_dataset' # Path of the dataset inside the cloud storage\n",
        "DATASET_DIR = 'dataset'\n",
        "DATASET_NAME = 'ctscans'\n",
        "dataset_sub_folder = ''\n",
        "!cp -r {G_DRIVE_DIR} {DATASET_DIR}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omV2fGORaPQT"
      },
      "source": [
        "#get list of classes\n",
        "def listdir_nohidden(path):\n",
        "  return [f for f in os.listdir(path) if not f.startswith('.')]\n",
        "\n",
        "CLASSES_LIST = sorted(listdir_nohidden(DATASET_DIR))\n",
        "print(CLASSES_LIST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCkrg0DSYNCv"
      },
      "source": [
        "## 3) Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL8o67APV5PK"
      },
      "source": [
        "img_width, img_height = 224, 224\n",
        "train_data_dir = DATASET_DIR \n",
        "\n",
        "batch_size = 8\n",
        "seed =13\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    channel_shift_range=10,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    validation_split = 0.2,\n",
        "    )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory = train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = seed,\n",
        "    class_mode='categorical',\n",
        "    subset = 'training')\n",
        "\n",
        "validation_generator  = train_datagen.flow_from_directory(\n",
        "    directory = train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = seed,\n",
        "    class_mode='categorical',\n",
        "    subset = 'validation')\n",
        "\n",
        "nb_train_samples = train_generator.n\n",
        "nb_validation_samples = validation_generator.n\n",
        "n_classes = train_generator.num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iovw4ibV5PC"
      },
      "source": [
        "## 4) Pretrained model selection (Transfer Learning approach)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFcjYtG7V5PE"
      },
      "source": [
        "use_the_model = 8\n",
        "model_name = 'train'\n",
        "epoch_num = 20\n",
        "\n",
        "if use_the_model is 1:\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "    model_name = 'InceptionV3'\n",
        "    \n",
        "elif use_the_model is 2: \n",
        "    base_model = VGG16(weights='imagenet', include_top=False)\n",
        "    model_name = 'VGG16'\n",
        "    \n",
        "elif use_the_model is 3: \n",
        "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "    model_name = 'ResNet50'\n",
        "    \n",
        "elif use_the_model is 4: \n",
        "    base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n",
        "    model_name = 'InceptionResNetV2'\n",
        "\n",
        "elif use_the_model is 5: \n",
        "    base_model = NASNetLarge(input_shape=(331,331,3), weights='imagenet', include_top=False)\n",
        "    model_name = 'NASNetLarge'\n",
        "\n",
        "elif use_the_model is 6: \n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
        "    model_name = 'MobileNetV2'\n",
        "    \n",
        "elif use_the_model is 7: \n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False)\n",
        "    model_name = 'DenseNet121'\n",
        "\n",
        "elif use_the_model is 8:\n",
        "   base_model = EfficientNetB2(weights=\"imagenet\", include_top=False)\n",
        "   model_name = 'EfficientNetB2'\n",
        "\n",
        "elif use_the_model is 9:\n",
        "   base_model = EfficientNetB3(weights=\"imagenet\", include_top=False)\n",
        "   model_name = 'EfficientNet3'\n",
        "\n",
        "print(\"({}) {} model loaded with {} epochs.\".format(model_name,use_the_model, epoch_num))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVu06wfeV5PN"
      },
      "source": [
        "##### 4.1) Add new top layers to the selected model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eYPfS43V5PO"
      },
      "source": [
        "x = base_model.output\n",
        "x = lay.GlobalAveragePooling2D()(x)\n",
        "x = lay.Dense(512,activation='relu')(x)\n",
        "x = lay.Dropout(0.2)(x)\n",
        "\n",
        "predictions = lay.Dense(n_classes,\n",
        "                    kernel_regularizer=regularizers.l2(0.005), \n",
        "                    activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RJMFgrpV5PQ"
      },
      "source": [
        "## 5) Compile the model\n",
        "#### Compile the model with SGD optimazer, and use top 1 accuracy metrics. Initialize one callback for the training logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHvlUcTUV5PR"
      },
      "source": [
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "RESULTS_DIR = 'results'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "csv_filename = os.path.join(RESULTS_DIR,model_name+'_training_log.csv')\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(csv_filename, separator=',', append=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw75tg3ZV5PU"
      },
      "source": [
        "## 6)Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Qn22UoNjV5PV"
      },
      "source": [
        "hist = model.fit(train_generator,\n",
        "                 steps_per_epoch = nb_train_samples // batch_size,\n",
        "                 validation_data = validation_generator,\n",
        "                 validation_steps = nb_validation_samples // batch_size,\n",
        "                 epochs = epoch_num,\n",
        "                 verbose = 1,\n",
        "                 callbacks = [csv_logger]\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7LMzwvVgsuC"
      },
      "source": [
        "## 7) Check training results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilxf9YsJdCm4"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n",
        "\n",
        "ax1.set_title('Accuracy')\n",
        "ax1.plot(hist.history['accuracy'])\n",
        "ax1.plot(hist.history['val_accuracy'])\n",
        "ax1.set(xlabel='epoch', ylabel='accuracy')\n",
        "ax1.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "ax2.set_title('Loss')\n",
        "ax2.plot(hist.history['loss'])\n",
        "ax2.plot(hist.history['val_loss'])\n",
        "ax2.set(xlabel='epoch', ylabel='loss')\n",
        "ax2.legend(['train', 'val'], loc='upper left')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjLDbVJLdGdu"
      },
      "source": [
        "## 8) Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXvufE5udAds"
      },
      "source": [
        "model.save('my_model_'+model_name) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CV8BRhCdWoY"
      },
      "source": [
        "## 9) Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9mIp5I1dfJ1"
      },
      "source": [
        "def prepare_img(img):\n",
        "  image = tf.keras.preprocessing.image.load_img(img)\n",
        "  input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "  input_arr /= 255\n",
        "  input_arr = np.array([input_arr]) \n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "  return input_arr\n",
        "\n",
        "#Load image form computer\n",
        "#uploaded = files.upload()\n",
        "#img_infer = list(uploaded)[0]\n",
        "\n",
        "#Load image from the VM or the Google Drive\n",
        "img_infer = 'path_to_a_sample.jpg'\n",
        "print('Running inference on: ' + img_infer)\n",
        "\n",
        "#Predict image\n",
        "predictions = model.predict(prepare_img(img_infer))\n",
        "\n",
        "#Show predictions for all classes\n",
        "for the_class, pred in sorted(zip(CLASSES_LIST,predictions[0])):\n",
        "  print('{}: {:.4f}'.format(the_class, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hsJ7IFbpErp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}